<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Neural Nets, Connectionism, Perceptrons, etc. — Notebooks</title>
<style>
  :root {
    --bg: #f9f7f2;
    --text: #1a1a18;
    --link: #7a1a1a;
    --link-hover: #c0392b;
    --muted: #666;
    --border: #ccc9be;
    --quote-bg: #f0ede4;
    --code-bg: #edeae0;
  }
  * { box-sizing: border-box; margin: 0; padding: 0; }
  body {
    font-family: Georgia, 'Times New Roman', serif;
    font-size: 16px;
    line-height: 1.7;
    background: var(--bg);
    color: var(--text);
    max-width: 760px;
    margin: 0 auto;
    padding: 2rem 1.5rem 5rem;
  }
  .site-nav {
    font-size: 0.88em;
    color: var(--muted);
    margin-bottom: 2rem;
    font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
  }
  .site-nav a { color: var(--link); }
  .site-nav a:hover { color: var(--link-hover); }
  h1 {
    font-size: 1.8rem;
    font-weight: normal;
    line-height: 1.25;
    margin-bottom: 0.3rem;
  }
  .last-modified {
    font-size: 0.85em;
    color: var(--muted);
    font-style: italic;
    margin-bottom: 1.8rem;
    font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
  }
  h2 { font-size: 1.2rem; font-weight: bold; margin: 1.8rem 0 0.5rem; }
  h3 { font-size: 1.05rem; font-weight: bold; margin: 1.4rem 0 0.4rem; }
  p { margin: 0.85rem 0; }
  a { color: var(--link); text-decoration: none; }
  a:hover { color: var(--link-hover); text-decoration: underline; }
  blockquote {
    background: var(--quote-bg);
    border-left: 3px solid var(--border);
    padding: 0.6rem 1rem;
    margin: 1rem 0;
    font-style: italic;
    color: #444;
  }
  ul, ol { margin: 0.8rem 0 0.8rem 1.6rem; }
  li { margin: 0.3rem 0; }
  code {
    background: var(--code-bg);
    padding: 0.1em 0.3em;
    border-radius: 2px;
    font-family: 'Courier New', monospace;
    font-size: 0.88em;
  }
  pre {
    background: var(--code-bg);
    border: 1px solid var(--border);
    padding: 0.8rem 1rem;
    border-radius: 3px;
    overflow-x: auto;
    margin: 1rem 0;
  }
  pre code { background: none; padding: 0; }
  hr { border: none; border-top: 1px solid var(--border); margin: 2rem 0; }
  .footer {
    margin-top: 3rem;
    font-size: 0.85em;
    color: var(--muted);
    font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
  }
</style>
</head>
<body>

<div class="site-nav">
  <a href="../index.html">← Notebooks</a>
</div>

<h1>Neural Nets, Connectionism, Perceptrons, etc.</h1>
<div class="last-modified">Last modified: 12 Feb 2026 11:40</div>

<h1 id="neural-nets-connectionism-perceptrons-etc.">Neural Nets,
Connectionism, Perceptrons, etc.</h1>
<p>Notes on artificial neural networks — from perceptrons to deep
learning.</p>
<h2 id="historical-background">Historical Background</h2>
<p>The perceptron (Rosenblatt, 1958) was the first trainable neural
network. Minsky &amp; Papert’s <em>Perceptrons</em> (1969) showed its
limitations (it can’t learn XOR), dampening enthusiasm for two
decades.</p>
<p>The backpropagation algorithm (Rumelhart, Hinton, Williams, 1986)
enabled training of multi-layer networks, reviving the field.</p>
<h2 id="why-deep-learning-works-partial-answers">Why Deep Learning Works
(Partial Answers)</h2>
<ul>
<li><strong>Representation learning</strong>: hidden layers learn useful
feature representations</li>
<li><strong>Lottery ticket hypothesis</strong>: large networks contain
well-initialized sub-networks</li>
<li><strong>Implicit regularization</strong>: SGD has a bias toward
“simpler” solutions</li>
<li><strong>Double descent</strong>: generalization can improve even as
models interpolate training data</li>
</ul>
<h2 id="architecture-zoo">Architecture Zoo</h2>
<ul>
<li><strong>MLP</strong>: fully connected layers; the baseline</li>
<li><strong>CNN</strong>: convolutional layers exploit spatial locality
and translational equivariance</li>
<li><strong>RNN/LSTM</strong>: handle sequences with recurrent
connections; largely supplanted by Transformers</li>
<li><strong>Transformer</strong>: attention mechanisms; now dominant in
language, vision, and much else</li>
<li><strong>GNN</strong>: extend deep learning to graph-structured
data</li>
</ul>
<h2 id="concerns">Concerns</h2>
<p>Adversarial examples, overconfident predictions, poor calibration,
brittleness to distribution shift. The gap between benchmark performance
and real-world reliability remains large in many domains.</p>
<h2 id="see-also">See Also</h2>
<ul>
<li><a href="ai.html">Artificial Intelligence</a></li>
<li><a href="statistics.html">Statistics</a></li>
</ul>

<hr>
<div class="footer">
  <a href="../index.html">Notebooks index</a>
</div>

</body>
</html>
